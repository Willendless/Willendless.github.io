---
layout: "post"
title: 并行架构和编程（?）
mathjax: true
---

## 1. GPU Architecture \& CUDA programming

+ graphic mode: fragment shader
+ compute mode

## 2. CUDA 抽象

+ 多维并行执行实体抽象
  + 两层抽象
    + thread blocks
    + threads
  + **注意**: programmer指定每一维的大小
    + 每个block各个维度的thread数
    + 总的block维度
+ cuda thread: 
  + 类似于ISPC中的program instance
+ GPU内存访问
  + memcpy primitive: `cudeMemcpy`
+ CUDA device memory model
  + **per block mem**: *software controlled*
    + `__shared__`: shared memory for per block threads
    + `__syncthreads()`
  + **per thread mem**: regs
  + **device global mem**
    + `cudaMalloc`

## 3. CUDA 实现

硬件和编译器

+ 编译器编译时限制内存以及块内线程数
+ GPU上有thread block scheduler
  + 线程池: 向worker thread动态分配任务，并提前分配资源
+ **warp**: **能够同时执行的独立指令流数量**，即需要同时执行相同指令的cuda thread的数量
  + 每个指令流运行宽度为32的指令
  + 每个时钟周期从所有warps中选择

![](/assets/images/pp/1-5.png)

如上图的单个GPU thread block(SMM core, Streaming Multiprocessor)所示，

+ 64 warp: 64路multi-threading
+ 32-wide SIMD
+ 2-wide ILP **within a thread**
+ 每个周期可以从64个warp执行上下文中选择4个warp
+ 每个warp选择最多2个可运行指令（指令级别并行）
+ 总共$4 * 32 = 128$个cuda thread

NVIDIA GTX 980有16个上述SMM核

+ $16 * 128 = 2048$SIMD mul-add ALUs
+ 最多$16 * 64 = 1024$ interleaved warps（32,768 CUDA threads)

注意: 调度单元和编程抽象单元是block和thread，调度器负责将整数个block分配到warp存储中。

+ 注意1: **GPU无法抢占threads**。一旦资源设置好，threads会run to completion。
+ 注意2: **GPU线程间是可能有依赖的**，因此有`__syncthreads`, `atomicAdd`等原语，但是GPU调度器不能保证调度的顺序

### 3.1. 什么是warp

+ CPU side: 单个运行32-wide SIMD指令的执行上下文
+ GPU side: 32个有相同指令流的上下文
