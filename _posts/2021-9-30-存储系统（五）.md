---
layout: "post"
title: 存储系统（四）Multi-disk systems & RAID
author: LJR
category: 存储系统
tags:
    - storage systems
---

> Transparency enables deployment.

**RAID**: Redundant Array of Inexpensive Disks

**Fail-Stop fault model**: a disk can only be in one of two states, working or failed and the disk controller can easily observe the failure.

## 1. motivation of RAID

+ axis 1: **storage capacity**
+ axis 2: **performance**
  + bandwidth (MB/second)
    + stream data from multiple disks
  + throughput (IOs/second)
    + concurrent requests to multiple disks
+ axis 3: **reliability**
  + tolerate partial and full disk failures

**performance metrics**

+ **single-request latency**: reveal how much parallelism can exist during a single logical I/O operation
+ ***steady-state throughput***: total bandwidth of many concurrent requests

## 2. performance

### 2.1. Disk load Characteristics

+ load imbalances:
  + **fixed**: some data is always hot
  + **migrating**: hot data changes over time
    + static data partitioning to evenly distribute IO requests is difficult
+ metric: **disk queue lengths**

### 2.2. load balancing

+ **fixed data placement**
  + predictable but not equals to good performance
+ **dynamic data placement**
  + label file as hot, separate across multiple disks
+ **disk striping**
  + data interleaved across multiple disks
  + design choice: **choose stripe unit size**
    + too small
      + good load balancing with small transfer time
      + extra seeks/accesses
    + too big:
      + no parallel transfer
      + poor load balancing

## 3. reliability

+ **metrics**: MTBF, Mean Time Between Failures
  + HDDs: 1-13% replaced annually
  + SSDs: 1-3% replaced annually
+ we need data redundancy to tolerate disk failures
  + replication
  + error-correcting codes
  + erasure-correcting codes

### 3.1. mirror

+ **mirror**: two copies of each write
  + reliability: good
  + storage capacity: doubles the cost
  + performance
    + reads: read in parallel from both drives
    + writes: response time = Max{RT of disk1, RT of disk2}
+ combine mirroring and striping
  + **first stripe then mirror each stripe unit**
  + **first mirror the data, then stripe**

### 3.2. parity

+ **RAID 4**: one extra disk and all writes update parity disk
  + parity disk becomes the bottleneck
  + fault free read/write
    + write: 2 read and 2 write, **read-modify-write**
  + degraded read/write
+ performance
  + reads go only to the data disks
  + all write go to the parity disks

![](/assets/images/ss/5-1.png)

+ **RAID 5**: distribute the parity across all disks
+ **RAID 6**: 2 striped parity codes
+ **RAID N+3**: 3 striped parity codes

## 4. other problems

### 4.1. RAID mapping problems

For map logical block A to physical block

`# of Disk = (A % stripe size) / chunk size`

`# of offset within a disk = (A / stripe size) * chunk size + A % chunk size`

### 4.2. consistent update problem

When update mirror and data disks, we want the state of both disks to change atomically

**Solution**: WAL

But the cost of logging to disk on every write is too high, most RAID hardware **writes log to a battery backed non-volatile RAM.**

### 4.3. RAID 术语

+ RAID 0: only striping
+ RAID 1: mirroring of independent disks
  + RAID 1+0: **stripe of mirrors**, first stripe than mirror
  + RAID 0+1: **mirror of stripes**, first mirror than stripe
+ RAID 2: fine-grained data striping plus hamming code disks
  + bit level striping
+ RAID 3: fine-grained data striping plus parity disk
  + byte level striping
+ RAID 4: coarse-grained data striping plus parity disk
+ RAID 5: stripe parity
+ RAID 6: double parity
+ RAID N+3: triple parity

## 5. Disk array systems

### 5.1. reconstructing failed drive data

**reliability of disk arrays with no repair**

+ per disk: $MTBF = \frac{\sum{(t_{down}-t_{up})}}{num\;of\;failures}$
+ striped array of N disks: $MTBF = mean\;time\;to\;first\;disk\;failure = \frac{\sum{(t_{down}-t_{up})}}{disks*failures\;per\;disk} = \frac{MTBF_{drive}}{N}$
+ striped + mirrored array of N + N disks
  + $MTBF = MTBF_{pair} / N$
  + $MTBF_{pair} = (MTBF_{drive} / 2) + MTBF_{drive} = 1.5 * MTBF_{drive}$
+ 4N data disks and N parity disks
  + $MTBF = MTBF_{stripe} / N$
  + $MTBF_{stripe} = (MTBF_{drive}/5) + (MTBF_{drive}/4) = 0.45 * MTBF_{drive}$

![](/assets/images/ss/5-2.png)

+ disk rebuild and disk sparing
  + tradeoff: **reliability vs performance**
    + longer rebuild time: vulnerable to 2nd failure
    + shorter rebuild time: impact user app performance

**reliability of disk arrays with rebuild**

+ MTTR: mean time to rebuild
  + no data loss if repair completes before 2nd failure
+ MTTDL: mean time to data loss
  + solve Markov model of array states

### 5.2. disk array operation mode

+ normal mode: maximum efficiency
+ degraded mode
  + some disk unavailable
+ rebuild mode
  + reconstructing lost disk's contents onto space
