---
title: 存储系统（三）file system layout
author: LJR
category: 存储系统
tags:
    - storage systems
---

> **File system storage layout**: map file system structures and data to LBNs

+ problem 1: mapping file data to storage locations.
+ problem 2: tracking and allocating free space.
  + solution 1: free list
  + solution 2: bitmap
  + solution 3: free extent list (separate list)
    + extent: a contiguous range of free blocks

## 1. storage layout for HDDs

![](/assets/images/ss/3-1.png)

+ HDDs
  + **problem**: how to thoroughly use disk's bandwidth?
  + **seek time depends on distance**: we need locality!
  + **positioning dominates small transfers**: we need larger transfer size!
+ two optimization technology
  + **locality**: minimize seeking between requests
    + **putting related things "close" to each other**
    + benefits: 2x range
  + **transfer size**: amortize positioning costs
    + **batch && prefetching**
    + benefits: 10x range

### 1.1. FFS

> Co-locate the file's data and metadata blocks so sequential reads will be quick. LFS, instead, will write data in the order it arrived.

![](/assets/images/ss/3-2.png)

+ locality: cylinder groups(allocation groups)
  + data block next to its inode block
  + file data next to its directory's inode and data
  + file within a same directory next to each other
  + **directory allocation**: find the group with low number of allocated directories (**balance directories across groups**) and a high number of free inodes (to subsequently be able to allocate a bunch of files), and put directory inode and data into that group
  + **file allocation**
    + allocate file data blocks and inode in the same group
    + place all files that are in the same directory in the cylinder group of the directory
  + 注意: 现代磁盘驱动没有导出足够的让文件系统知道cylinder的使用情况的信息，因此文件系统仅仅是将连续的磁盘地址空间组织成block group。
+ large transfers
  + **larger FS block size**: more data per disk read/write
  + **allocate contiguous blocks when possible**
    + start allocation search from last block #
  + **prefetching**: fetch more data than requested

### 1.2. However

+ **small files remain a problem**, performance may degrade over 50% with aging
+ most files are small, 70% smaller than 8kB
  + levels of indirection (director, inode, data, ...)
+ Solution: **group small files and metadata for larger I/Os**
  + co-locate related information and access together
  + over aggressiveness costs little

### 1.3. LFS

> LFS optimize for write (change random write to sequential write and improve locality), and serve read from large cache.

+ idea: **amortization**, try to achieve large writes
  + buffer and remap new versions of data into large segments
  + segment-sized writes make efficient use disk head
+ an example of **shadow paging/copy-on-write**: not in-place update
  + completely write a segment to replace several older blocks
    + atomic writes help with consistency
  + **cleaning** reclaims space
    + how: **condense still-live blocks from several current segments**

#### 1.3.1. implementation details

##### 1.3.1.1. how much to buffer

##### 1.3.1.2. how to find inodes

+ inode map
+ checkpoint region

##### 1.3.1.3. garbage collection

##### 1.3.1.4. crash recovery and the log

## 2. storage layout for flash SSDs

+ mechanical performance drivers aren't present
+ modern FTLs do LFS-like remapping into SSD blocks

### 2.1. F2FS

+ Trick 1: **set segment size = SSD block size**
  + fine-grained mapping and cleaning only in F2FS
+ Trick 2: **separate hot/cold data**
  + put hot data in different segments than cold data
